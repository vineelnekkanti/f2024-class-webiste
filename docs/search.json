[
  {
    "objectID": "week1_materials_starter.html",
    "href": "week1_materials_starter.html",
    "title": "Week1 materials",
    "section": "",
    "text": "The following sections of our book R for Data Science( first portion of the course book ) are included in the first week:\n\nIntroduction\nWorkflow basics\n\n\n\n\nInternal help: posit support\nExternal help: stackoverflow\nAdditional materials: posit resources\nCheat Sheets: posit cheat sheets\n\nWhile I use the book as a reference the materials provided to you are custom made and include more activities and resources. If you understand the materials covered in this document there is no need to refer to other sources. If you have any troubles with the materials don’t hesitate to contact me or check the above sources."
  },
  {
    "objectID": "week1_materials_starter.html#intro-to-r",
    "href": "week1_materials_starter.html#intro-to-r",
    "title": "Week1 materials",
    "section": "",
    "text": "The following sections of our book R for Data Science( first portion of the course book ) are included in the first week:\n\nIntroduction\nWorkflow basics\n\n\n\n\nInternal help: posit support\nExternal help: stackoverflow\nAdditional materials: posit resources\nCheat Sheets: posit cheat sheets\n\nWhile I use the book as a reference the materials provided to you are custom made and include more activities and resources. If you understand the materials covered in this document there is no need to refer to other sources. If you have any troubles with the materials don’t hesitate to contact me or check the above sources."
  },
  {
    "objectID": "week1_materials_starter.html#getting-started-aka-running-code-in-r",
    "href": "week1_materials_starter.html#getting-started-aka-running-code-in-r",
    "title": "Week1 materials",
    "section": "Getting Started aka Running code in R",
    "text": "Getting Started aka Running code in R\nTo run and execute code inside a code chunk simply click the Run Code button or make sure that your cursor is anywhere in the line that you want to execute and press Cmd(Mac)/Ctrl(Windows) + Enter to run a single line of code or highlight multiple line and then press Cmd/Ctrl + Enter. Let’s try with the below code\n\n\n\n\n\n\n\n\n\nPackages installation\nYou will need to install the packages first before be able to use functions and datasets they contain. This is a one time task unless you uninstall R& RStudio or you change your computer. We will need to install a few packages, among them the most important is tidyverse. Tidyverse is the main package for the first part of the semester, it is a bundle package (meaning it contains multiple packages that have different purposes e.g., dplyr for manipulations, ggplot for visualizations)\n\n\n\n\n\n\n\n\n\n\nLoad packages\nThis is a critical task. Every time you open a new RStudio session you will need to load the packages. Failing to do so will incur in the most common errors among beginners (e.g., function not found or object not found)\n\n\n\n\n\n\n\n\nTake careful note of the conflicts message that’s printed when you load the tidyverse. It tells you that dplyr overwrites some functions in base R. If you want to use the base version of these functions after loading dplyr, you’ll need to use their full names: stats::filter() and stats::lag().\n\n\nNeed help\nIf you are stuck promise me not to quit! You are a beginner so it will happen. Just pay attention to the error message and look at the below option to find a solution:\n\nlook into the R community or Stackoverflow\nleverage LLM (e.g., ChatGPT)\nuse help with R documentation (e.g., try ?mean below)\ncheck examples of how to use a certain function (e.g., try example(“mean”) below)\n\nNB During the exams you can only use the last two options so make sure you master them!"
  },
  {
    "objectID": "week1_materials_starter.html#workflow-basic-script",
    "href": "week1_materials_starter.html#workflow-basic-script",
    "title": "Week1 materials",
    "section": "Workflow basic script",
    "text": "Workflow basic script\nYou can use R as a calculator..\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Object using the Assignement operator\nBut it can do much more.. so we need to learn how to create and manage object using the assignment operator.\n\n\n\n\n\n\n\n\n&lt;- is the assign operator and it means you are assigning value to an object/variable. You can then call and use the object created later.\nThe shortcut option/alt + - will create the assign symbol\n\n\nHow to manage object?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to name your objects?\nObject names must start with a letter, and can only contain letters, numbers, _ and .. You want your object names to be descriptive, so you’ll need a convention for multiple words.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow let’s check your object creation understanding. Given the object below:\n\n\n\n\n\n\n\n\nWhat happen if I run the following lines; why?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActivity 1: Create objects by using the assignment operator (6 minutes) [write code just below each instruction; finally use Teams RStudio - Forum channel for help on the in-class activities/homework or if you have other questions]\n#a. An object named “today” that is equal to todays’ date\n\n\n\n\n\n\n\n\n#b. An object named “forty” that is equal to 6*5 +10\n\n\n\n\n\n\n\n\n#c. An object named “basic_sum” that is equal to 1+2+3+4+5\n\n\n\n\n\n\n\n\n#d. Write also the code to print the today object\n\n\n\n\n\n\n\n\n\n\n\nUsing functions\nFunctions are the real reason why you should use R. There are too many functions to go over or even try remember. In fact, each package will give you access to a different set of functions and sometimes they will use the same name (e.g., remember the conflict with the filter function above). However, the good news is that you don’t need to memorize them but understand how they work. Let’s start with a basic example, how can we create a sequence of numbers in R?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActivity 2: Use basic functions (8 minutes) [write code just below each instruction; finally use Teams RStudio - Forum channel for help on the in class activities/homework or if you have other questions]\n#a. Learn more about the sum function (hint: use the help feature covered today)\n\n\n\n\n\n\n\n\n#b. Use the sum function to compute the sum of all the numbers from 1 to 1000.\n\n\n\n\n\n\n\n\n#c. Assign the above function to an object named “my_first_function”\n\n\n\n\n\n\n\n\n#d. Print the object “my_first_function”"
  },
  {
    "objectID": "student-dashboard.html",
    "href": "student-dashboard.html",
    "title": "Dr. B Learning Leaderboard",
    "section": "",
    "text": "import { Select } from \"@observablehq/inputs\";\nviewof tableSelector = Select([\"Overall Learning Score\", \"Coding Checkups Score\", \"In-Class Participation\", \"Teams Participation\", \"Professionalism\", \"Others\"], {label: \"Choose a category:\"})"
  },
  {
    "objectID": "student-dashboard.html#section",
    "href": "student-dashboard.html#section",
    "title": "Dr. B Learning Leaderboard",
    "section": "",
    "text": "html`&lt;div id=\"table-container\" style=\"overflow-x:auto; max-width: 100%;\"&gt;&lt;/div&gt;`\n\n\n\n\n\n\n\n{\n  const selectedTable = tableSelector;\n  let tableHTML;\n\n  if (selectedTable === \"Overall Learning Score\") {\n    tableHTML = final_overall_performance_table_html;\n  } else if (selectedTable === \"Coding Checkups Score\") {\n    tableHTML = final_weekly_activity_table_html;\n  } else if (selectedTable === \"In-Class Participation\") {\n    tableHTML = final_inclass_participation_table_html;\n  } else if (selectedTable === \"Teams Participation\") {\n    tableHTML = final_teams_participation_table_html;\n  } else if (selectedTable === \"Professionalism\") {\n    tableHTML = final_professionalism_table_html;\n  } else if (selectedTable === \"Others\") {\n    tableHTML = final_survey_test_table_html;\n  } else {\n    tableHTML = final_overall_performance_table_html;\n  }\n\n  document.getElementById(\"table-container\").innerHTML = tableHTML;\n  // Explicitly return nothing to prevent \"undefined\" from being displayed\n  return \"Reach out to Dr. B or Venkata for any queries regarding your scores.\";\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nStay positive and keep pushing forward! If you’re working hard but not yet where you want to be, there’s plenty of time to improve. If you’re doing well, remember that rankings can change, so keep up the effort. Consistent work will help you reach or maintain your goals. You’ve got this"
  },
  {
    "objectID": "practice_R.html",
    "href": "practice_R.html",
    "title": "R Practice",
    "section": "",
    "text": "This interface helps you to improve your R skills. Here you can access to a data set called starwars"
  },
  {
    "objectID": "practice_R.html#use-pipes",
    "href": "practice_R.html#use-pipes",
    "title": "R Practice",
    "section": "Use Pipes",
    "text": "Use Pipes\n\n\n\n\n\n\nNote:\n\n\n\nYou may not be able to use a pipe on this website. So you can copy it from here |&gt;\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Faculty",
    "section": "",
    "text": "Dr. Biagio Palese - Dr. Biagio Palese’s (a.k.a. Dr. B) teaching and research interests embrace information systems, data analytics, artificial intelligence, creators’ economy, systems beyond firms control and customer service.\nHe’s a tidyverse certified instructor trainer, teaches coding workshops globally, introducing students to the tidyverse. Passionate about teaching and research, he involves students in open-source software projects. Experiences in diverse teams contribute to his academic and personal growth.\nHe also co-hosts The Gateway podcast, launched in 2021, aimed at exposing students to technology trends and topics, accessible online on major podcasting platforms."
  },
  {
    "objectID": "index.html#instructor",
    "href": "index.html#instructor",
    "title": "Faculty",
    "section": "",
    "text": "Dr. Biagio Palese - Dr. Biagio Palese’s (a.k.a. Dr. B) teaching and research interests embrace information systems, data analytics, artificial intelligence, creators’ economy, systems beyond firms control and customer service.\nHe’s a tidyverse certified instructor trainer, teaches coding workshops globally, introducing students to the tidyverse. Passionate about teaching and research, he involves students in open-source software projects. Experiences in diverse teams contribute to his academic and personal growth.\nHe also co-hosts The Gateway podcast, launched in 2021, aimed at exposing students to technology trends and topics, accessible online on major podcasting platforms."
  },
  {
    "objectID": "index.html#teaching-assistant",
    "href": "index.html#teaching-assistant",
    "title": "Faculty",
    "section": "Teaching Assistant",
    "text": "Teaching Assistant\n\nVenkata Surya Vineel Nekkanti - Venkata is currently pursuing a graduate degree in Management Information Systems at Northern Illinois University. With five years of experience, he has held various roles focused on process improvements through data analysis and leveraging DevOps technologies within the BFSI sector in the NAM region. He has a strong interest in the intersection where business meets technology.\nBeyond his academic pursuits, he is a devoted Sci-Fi enthusiast, enjoying both books and movies in the genre, besides George R.R. Martin’s world of fantasy. He also loves to play badminton."
  },
  {
    "objectID": "index.html#office-hours",
    "href": "index.html#office-hours",
    "title": "Faculty",
    "section": "Office Hours",
    "text": "Office Hours\n\n\n\nInstructor\nBooking URL\n\n\n\n\nDr. B &/or Venkata\nBook Here\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen booking office hours, double-check the name of the staff member you want to book the office hours with using the “Select Staff” drop down. Moreover, please keep in mind that the default office hours format is virtual (MS Teams meeting). If you prefer to meet in person, please check with us our in-person availability before booking."
  },
  {
    "objectID": "coming-soon.html",
    "href": "coming-soon.html",
    "title": "Content Coming Soon",
    "section": "",
    "text": "🚧 Coming Soon 🚧\n\n\nUnder development come back later!\n\n\nThank you for your patience.",
    "crumbs": [
      "Course Overview",
      "Course Chapters",
      "Chapter 1"
    ]
  },
  {
    "objectID": "chapter0.html",
    "href": "chapter0.html",
    "title": "Chapter 0: Welcome to OMIS 482",
    "section": "",
    "text": "The beginning of our journey\n\n\n\n\nWelcome to a transformative learning adventure designed to unveil the intricacies of predictive modeling analytics. This book stands as your gateway to a world where data speaks volumes, patterns emerge from chaos, and predictions become possible. We are about to embark on a journey that will not only educate but also inspire, as we delve deep into the major topics that form the backbone of predictive modeling analytics.\nThis course, meticulously structured and rich in content, is entirely based on the powerful R programming language, a tool embraced by statisticians, data scientists, and researchers worldwide. Fear not if these terms seem unfamiliar or if programming sounds like a foreign language; this book is crafted with you in mind. We start from the basics, building a strong foundation that will support your learning journey, ensuring that every step you take is one of confidence and understanding.\nWe are excited to announce that we worked hard to create a custom built course that leverages state of the art technologies and tools. Thanks to them we can ensure that you will have continuous access to all the course materials from any device, anytime, anywhere. This eliminates the need for software installations on your personal devices, making your learning experience smooth and hassle-free. For those of you interested in exploring further, R and RStudio, an IDE part of Posit, are free and open-source software that you can install and use. They are a powerful tools that will enhance your coding experience and provide you with additional capabilities accessible during and after the semester ends.\nAs we navigate through the chapters, you will find that the book is not just a repository of knowledge, but also a companion in your learning. Interactive activities, real-world examples, and hands-on exercises are interwoven throughout the pages, making the learning process not just educational, but also engaging and enjoyable. Yes, coding can be fun, and you are about to discover just how rewarding it can be.\nThis class is a celebration of learning, a space where curiosity is nurtured, and mistakes are embraced as stepping stones to mastery. We believe in the power of practice, and as the old adage goes, practice indeed makes perfect. The activities and challenges presented in this book are designed to provide you with ample opportunities to apply what you’ve learned, solidifying your understanding and enhancing your skills.\nDiversity is the spice of life, and so is the case in learning. This course does not assume any previous knowledge of R programming or data analytics. Whether you are a complete beginner or have dabbled in data science before, you will find the content accessible, challenging, and most importantly, rewarding. Every concept is explained with clarity, every challenge is an opportunity to learn, and every success is a moment to celebrate.\nWe understand that the journey of learning coding and data analytics can be daunting, but you are not alone. This book is your companion, your guide, and your mentor. It is packed with all the materials you need to succeed, carefully designed and curated by your professor to ensure a comprehensive and enjoyable learning experience.\nSo, open your minds, ready your computers, and let’s dive into the fascinating world of predictive modeling analytics. Together, we will demystify the complexities of R programming, unravel the mysteries of data, and uncover the secrets of predictive modeling. Welcome to a journey of discovery, learning, and growth. Welcome to the world of data analytics. Let the adventure begin!\n\n\nEach one of us is unique! We celebrate that and acknowledged that in the creation of this book. The below personas were kept in mind when design and creating the content for this class. They reflect the diverse backgrounds, academic pursuits, motivations and career aspirations of business students, ensuring that the course content can be tailored to meet their specific needs and interests.\n\nName: Mario\n\nAge: 22\nBackground: Senior majoring in Business Administration. First-generation college student of Italian descent. Works full-time in a local supermarket to support himself and his family.\nLearning Goals: Wants to understand predictive modeling to make data-driven decisions in business settings.\nChallenges: Balancing a full-time job and academic responsibilities. Has basic Excel skills but is new to R programming.\nMotivation: Aims to be the first in his family to graduate from college and aspires to manage his own business in the future.\n\nName: Aisha\n\nBackground: Senior in Marketing. Indian-American, with a keen interest in digital marketing. Works part-time at a digital marketing agency.\nLearning Goals: Wants to leverage data analytics for targeted marketing and customer segmentation.\nChallenges: Has experience with social media analytics but is new to more advanced predictive modeling techniques.\nMotivation: Eager to excel in digital marketing and bring innovative data-driven strategies to her workplace.\n\nName: Shanice\n\nBackground: Shanice, a 22-year-old senior majoring in Finance. African-American, actively involved in the college’s investment club. Receives financial aid and works part-time in a bank.\nLearning Goals: Aims to apply predictive modeling in financial analysis and investment strategies.\nChallenges: Has a strong background in quantitative methods but limited experience in programming.\nMotivation: Aspires to work in investment banking and believes that strong data analytics skills are crucial.\n\nName: Taylor\n\nBackground: Taylor, a 22-year-old senior majoring in International Business, has a bicultural background, with parents who immigrated from Korea. She has a basic understanding of R programming.\nLearning Goals: Taylor aims to better understand how data analytics can be applied in international business, particularly in diverse cultural contexts.\nChallenges: Finding resources that apply data analytics in international scenarios can be challenging. Taylor is also looking to deepen their understanding of R programming.\nNeeds: Taylor is driven by a desire to forge their own path and make a name for themselves, separate from their family’s influence.\n\nName: Serena\n\nBackground: Serena is a 22-year-old senior majoring in Marketing. Raised in a multicultural family, Serena has a unique worldview and is interested in consumer behavior. She has some prior experience with R from a previous internship.\nLearning Goals: Serena aims to integrate data analytics into marketing strategies. She wants to solidify her R programming skills and understand how to analyze consumer data effectively.\nChallenges: Balancing theory with practical application can sometimes be challenging for Serena. She is looking for a course that provides hands-on experience and real-world examples.\nMotivations: Serena is driven by a desire to set a positive example for her younger siblings and to capitalize on the educational opportunities afforded to her.\n\nName: Bryan\n\nBackground: Bryan is a 21-year-old junior majoring in Management Information Systems. He is the first in his family to attend college and he is working part-time to support his education.\nLearning Goals: Bryan is keen to learn about technology and its applications in business. He sees this course as an opportunity to gain practical skills in R programming and predictive modeling.\nChallenges: Balancing work, school, and personal life is a constant struggle for Bryan. Bryan needs a learning resource that is flexible and accessible at any time.\nMotivations: Bryan is motivated by the desire to stand out in his field and secure a good job after graduation.\n\n\n\n\n\nYour Work Should Be Your Work :\n\nAll assignments must be completed individually. Collaboration is encouraged for learning but not for submitting assignments.\nYou are allowed to use AI tools to assist in your learning. However, ensure you fully understand the concepts and processes AI helps you with. AI tools are for learning enhancement, not for doing your work for you.\nAI tools are strictly prohibited in examinations and formally graded assignments. You should rely solely on your knowledge and understanding to complete them.\n\nResponsible Use of Class Resources:\n\nUse class resources solely for practicing and completing class assignments. Avoid using them for activities not related to this class.\nR and RStudio are open-source, but the class resources leverage a paid service and we have a limited budget for this class.\nExcessive or non-class related usage can lead to budget overruns. They will create frustrations and issue for everybody.\n\nMonitoring and Support:\n\nAs your instructor, I will have access to your work. This will allow me to monitor your progress and provide help when needed.\nKeep an open line of communication. I am here to help! If you’re struggling with the material or the technology, let me know sooner rather than later. Feel free to reach out via MS Teams or by booking an office hours appointment.\n\nRespect and Integrity:\n\nBe kind, respectful and polite.\nMaintain a high level of academic integrity and professionalism for your peers, me and the resources provided.\nAny form of dishonesty or disrespect will be addressed according to college policies.\n\nBy following these rules, you can ensure a productive, fair, and efficient learning environment for everyone in the class.\nFocus on Learning:\nMy primary focus and concern are your learning. I truly care that all of you understand and master all the materials that we will cover this semester. There are different components that are included in your learning evaluation:\n\nWeekly coding checkups: demonstration of understanding/mastering the weekly materials by completing custom designed coding checkups that will walk you through a semester long and complete data analytics project.\nIn-class participation: willingness to understanding/mastering by asking questions and/or demonstration of understanding/mastering by answering questions/solving activities during class time.\nTeams participation: willingness to understanding/mastering by asking questions and/or demonstration of understanding/mastering by answering questions/solving activities on the MS Teams class channel.\nProfessionalism: attitude towards learning (e.g., being on time, staying engaged, paying attention, being respectful etc.)\nOthers: participation to other learning enhancement initiatives (e.g., completing surveys, responding to polls etc.)\n\n\n\n\n\nThe following sections of our book R for Data Science( first portion of the course book ) are included in the first week:\n\nIntroduction\n\n\n\n\nInternal help: posit support\nExternal help: stackoverflow\nAdditional materials: posit resources\nCheat Sheets: posit cheat sheets\n\nWhile I use the book as a reference the materials provided to you are custom made and include more activities and resources. If you understand the materials covered in this document there is no need to refer to other sources. If you have any troubles with the materials don’t hesitate to contact me or check the above sources.\n\n\n\n\nIf you install R & RStudio on your own machine it is critical that you install all the required packages. You will need to install them be able to use functions and datasets they contain. This is a one time task unless you uninstall R & RStudio or you change your computer.\nLoading packages is also a critical task and it is more repetitive. Every time you open a new RStudio session you will need to load the packages using the library function. Failing to do so will incur in the most common errors among beginners (e.g., function not found or object not found)\nNB in this class we have a dynamic book & materials in which I take care of all the boring things for you so that you just focus on LEARNING ;-)\n\nOk great! This should be enough to start your journey. See you for more in the next chapter!",
    "crumbs": [
      "Course Overview",
      "Course Chapters",
      "Chapter 0"
    ]
  },
  {
    "objectID": "chapter0.html#class-introduction",
    "href": "chapter0.html#class-introduction",
    "title": "Chapter 0: Welcome to OMIS 482",
    "section": "",
    "text": "Welcome to a transformative learning adventure designed to unveil the intricacies of predictive modeling analytics. This book stands as your gateway to a world where data speaks volumes, patterns emerge from chaos, and predictions become possible. We are about to embark on a journey that will not only educate but also inspire, as we delve deep into the major topics that form the backbone of predictive modeling analytics.\nThis course, meticulously structured and rich in content, is entirely based on the powerful R programming language, a tool embraced by statisticians, data scientists, and researchers worldwide. Fear not if these terms seem unfamiliar or if programming sounds like a foreign language; this book is crafted with you in mind. We start from the basics, building a strong foundation that will support your learning journey, ensuring that every step you take is one of confidence and understanding.\nWe are excited to announce that we worked hard to create a custom built course that leverages state of the art technologies and tools. Thanks to them we can ensure that you will have continuous access to all the course materials from any device, anytime, anywhere. This eliminates the need for software installations on your personal devices, making your learning experience smooth and hassle-free. For those of you interested in exploring further, R and RStudio, an IDE part of Posit, are free and open-source software that you can install and use. They are a powerful tools that will enhance your coding experience and provide you with additional capabilities accessible during and after the semester ends.\nAs we navigate through the chapters, you will find that the book is not just a repository of knowledge, but also a companion in your learning. Interactive activities, real-world examples, and hands-on exercises are interwoven throughout the pages, making the learning process not just educational, but also engaging and enjoyable. Yes, coding can be fun, and you are about to discover just how rewarding it can be.\nThis class is a celebration of learning, a space where curiosity is nurtured, and mistakes are embraced as stepping stones to mastery. We believe in the power of practice, and as the old adage goes, practice indeed makes perfect. The activities and challenges presented in this book are designed to provide you with ample opportunities to apply what you’ve learned, solidifying your understanding and enhancing your skills.\nDiversity is the spice of life, and so is the case in learning. This course does not assume any previous knowledge of R programming or data analytics. Whether you are a complete beginner or have dabbled in data science before, you will find the content accessible, challenging, and most importantly, rewarding. Every concept is explained with clarity, every challenge is an opportunity to learn, and every success is a moment to celebrate.\nWe understand that the journey of learning coding and data analytics can be daunting, but you are not alone. This book is your companion, your guide, and your mentor. It is packed with all the materials you need to succeed, carefully designed and curated by your professor to ensure a comprehensive and enjoyable learning experience.\nSo, open your minds, ready your computers, and let’s dive into the fascinating world of predictive modeling analytics. Together, we will demystify the complexities of R programming, unravel the mysteries of data, and uncover the secrets of predictive modeling. Welcome to a journey of discovery, learning, and growth. Welcome to the world of data analytics. Let the adventure begin!\n\n\nEach one of us is unique! We celebrate that and acknowledged that in the creation of this book. The below personas were kept in mind when design and creating the content for this class. They reflect the diverse backgrounds, academic pursuits, motivations and career aspirations of business students, ensuring that the course content can be tailored to meet their specific needs and interests.\n\nName: Mario\n\nAge: 22\nBackground: Senior majoring in Business Administration. First-generation college student of Italian descent. Works full-time in a local supermarket to support himself and his family.\nLearning Goals: Wants to understand predictive modeling to make data-driven decisions in business settings.\nChallenges: Balancing a full-time job and academic responsibilities. Has basic Excel skills but is new to R programming.\nMotivation: Aims to be the first in his family to graduate from college and aspires to manage his own business in the future.\n\nName: Aisha\n\nBackground: Senior in Marketing. Indian-American, with a keen interest in digital marketing. Works part-time at a digital marketing agency.\nLearning Goals: Wants to leverage data analytics for targeted marketing and customer segmentation.\nChallenges: Has experience with social media analytics but is new to more advanced predictive modeling techniques.\nMotivation: Eager to excel in digital marketing and bring innovative data-driven strategies to her workplace.\n\nName: Shanice\n\nBackground: Shanice, a 22-year-old senior majoring in Finance. African-American, actively involved in the college’s investment club. Receives financial aid and works part-time in a bank.\nLearning Goals: Aims to apply predictive modeling in financial analysis and investment strategies.\nChallenges: Has a strong background in quantitative methods but limited experience in programming.\nMotivation: Aspires to work in investment banking and believes that strong data analytics skills are crucial.\n\nName: Taylor\n\nBackground: Taylor, a 22-year-old senior majoring in International Business, has a bicultural background, with parents who immigrated from Korea. She has a basic understanding of R programming.\nLearning Goals: Taylor aims to better understand how data analytics can be applied in international business, particularly in diverse cultural contexts.\nChallenges: Finding resources that apply data analytics in international scenarios can be challenging. Taylor is also looking to deepen their understanding of R programming.\nNeeds: Taylor is driven by a desire to forge their own path and make a name for themselves, separate from their family’s influence.\n\nName: Serena\n\nBackground: Serena is a 22-year-old senior majoring in Marketing. Raised in a multicultural family, Serena has a unique worldview and is interested in consumer behavior. She has some prior experience with R from a previous internship.\nLearning Goals: Serena aims to integrate data analytics into marketing strategies. She wants to solidify her R programming skills and understand how to analyze consumer data effectively.\nChallenges: Balancing theory with practical application can sometimes be challenging for Serena. She is looking for a course that provides hands-on experience and real-world examples.\nMotivations: Serena is driven by a desire to set a positive example for her younger siblings and to capitalize on the educational opportunities afforded to her.\n\nName: Bryan\n\nBackground: Bryan is a 21-year-old junior majoring in Management Information Systems. He is the first in his family to attend college and he is working part-time to support his education.\nLearning Goals: Bryan is keen to learn about technology and its applications in business. He sees this course as an opportunity to gain practical skills in R programming and predictive modeling.\nChallenges: Balancing work, school, and personal life is a constant struggle for Bryan. Bryan needs a learning resource that is flexible and accessible at any time.\nMotivations: Bryan is motivated by the desire to stand out in his field and secure a good job after graduation.\n\n\n\n\n\nYour Work Should Be Your Work :\n\nAll assignments must be completed individually. Collaboration is encouraged for learning but not for submitting assignments.\nYou are allowed to use AI tools to assist in your learning. However, ensure you fully understand the concepts and processes AI helps you with. AI tools are for learning enhancement, not for doing your work for you.\nAI tools are strictly prohibited in examinations and formally graded assignments. You should rely solely on your knowledge and understanding to complete them.\n\nResponsible Use of Class Resources:\n\nUse class resources solely for practicing and completing class assignments. Avoid using them for activities not related to this class.\nR and RStudio are open-source, but the class resources leverage a paid service and we have a limited budget for this class.\nExcessive or non-class related usage can lead to budget overruns. They will create frustrations and issue for everybody.\n\nMonitoring and Support:\n\nAs your instructor, I will have access to your work. This will allow me to monitor your progress and provide help when needed.\nKeep an open line of communication. I am here to help! If you’re struggling with the material or the technology, let me know sooner rather than later. Feel free to reach out via MS Teams or by booking an office hours appointment.\n\nRespect and Integrity:\n\nBe kind, respectful and polite.\nMaintain a high level of academic integrity and professionalism for your peers, me and the resources provided.\nAny form of dishonesty or disrespect will be addressed according to college policies.\n\nBy following these rules, you can ensure a productive, fair, and efficient learning environment for everyone in the class.\nFocus on Learning:\nMy primary focus and concern are your learning. I truly care that all of you understand and master all the materials that we will cover this semester. There are different components that are included in your learning evaluation:\n\nWeekly coding checkups: demonstration of understanding/mastering the weekly materials by completing custom designed coding checkups that will walk you through a semester long and complete data analytics project.\nIn-class participation: willingness to understanding/mastering by asking questions and/or demonstration of understanding/mastering by answering questions/solving activities during class time.\nTeams participation: willingness to understanding/mastering by asking questions and/or demonstration of understanding/mastering by answering questions/solving activities on the MS Teams class channel.\nProfessionalism: attitude towards learning (e.g., being on time, staying engaged, paying attention, being respectful etc.)\nOthers: participation to other learning enhancement initiatives (e.g., completing surveys, responding to polls etc.)",
    "crumbs": [
      "Course Overview",
      "Course Chapters",
      "Chapter 0"
    ]
  },
  {
    "objectID": "chapter0.html#getting-started",
    "href": "chapter0.html#getting-started",
    "title": "Chapter 0: Welcome to OMIS 482",
    "section": "",
    "text": "The following sections of our book R for Data Science( first portion of the course book ) are included in the first week:\n\nIntroduction\n\n\n\n\nInternal help: posit support\nExternal help: stackoverflow\nAdditional materials: posit resources\nCheat Sheets: posit cheat sheets\n\nWhile I use the book as a reference the materials provided to you are custom made and include more activities and resources. If you understand the materials covered in this document there is no need to refer to other sources. If you have any troubles with the materials don’t hesitate to contact me or check the above sources.\n\n\n\n\nIf you install R & RStudio on your own machine it is critical that you install all the required packages. You will need to install them be able to use functions and datasets they contain. This is a one time task unless you uninstall R & RStudio or you change your computer.\nLoading packages is also a critical task and it is more repetitive. Every time you open a new RStudio session you will need to load the packages using the library function. Failing to do so will incur in the most common errors among beginners (e.g., function not found or object not found)\nNB in this class we have a dynamic book & materials in which I take care of all the boring things for you so that you just focus on LEARNING ;-)\n\nOk great! This should be enough to start your journey. See you for more in the next chapter!",
    "crumbs": [
      "Course Overview",
      "Course Chapters",
      "Chapter 0"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "Chapter 1: Manipulations",
    "section": "",
    "text": "When working on a new dataset the beginning might not be easy\n\n\nThe following sections of our book R for Data Science( first portion of the course book ) are included in the second week:\n\nData Transformation: Sections: from 3 to 3.3 & part of 3.5 included\n\n\n\n\nInternal help: posit support\nExternal help: stackoverflow\nAdditional materials: posit resources\nCheat Sheets: posit cheat sheets\n\nWhile I use the book as a reference the materials provided to you are custom made and include more activities and resources. If you understand the materials covered in this document there is no need to refer to other sources. If you have any troubles with the materials don’t hesitate to contact me or check the above sources.\n\n\n\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n\n\n\nData Science model: Artwork by @allison_horst\n\n\n\n\n\n\nflights#dataset we will use --&gt; make sure you run library(nycflights13) before running this line of code\n\n# A tibble: 15,000 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     4      819            820        -1     1103           1129\n 2  2013    12     5     1238           1110        88     1342           1223\n 3  2013     8    19     1953           1959        -6     2141           2146\n 4  2013     4    14      608            610        -2      752            754\n 5  2013     4    29     1653           1700        -7     1815           1835\n 6  2013     4     5     1813           1729        44     2026           1937\n 7  2013     1    17     1740           1745        -5     2054           2120\n 8  2013     2    26      834            815        19     1031           1010\n 9  2013     2    20     1014           1000        14     1219           1221\n10  2013     3    22     1741           1736         5     2024           2029\n# ℹ 14,990 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n?flights # get a description of it\n#view(flights)# run this if you want to explore the entire dataset --&gt; which will open the dataset in the RStudio viewer.\nglimpse(flights)# run this if you want a summary of the dataset \n\nRows: 15,000\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 12, 8, 4, 4, 4, 1, 2, 2, 3, 1, 2, 12, 8, 7, 9, 9, 12…\n$ day            &lt;int&gt; 4, 5, 19, 14, 29, 5, 17, 26, 20, 22, 25, 18, 13, 5, 29,…\n$ dep_time       &lt;int&gt; 819, 1238, 1953, 608, 1653, 1813, 1740, 834, 1014, 1741…\n$ sched_dep_time &lt;int&gt; 820, 1110, 1959, 610, 1700, 1729, 1745, 815, 1000, 1736…\n$ dep_delay      &lt;dbl&gt; -1, 88, -6, -2, -7, 44, -5, 19, 14, 5, 4, -2, -5, -7, 1…\n$ arr_time       &lt;int&gt; 1103, 1342, 2141, 752, 1815, 2026, 2054, 1031, 1219, 20…\n$ sched_arr_time &lt;int&gt; 1129, 1223, 2146, 754, 1835, 1937, 2120, 1010, 1221, 20…\n$ arr_delay      &lt;dbl&gt; -26, 79, -5, -2, -20, 49, -26, 21, -2, -5, -4, -19, -9,…\n$ carrier        &lt;chr&gt; \"B6\", \"EV\", \"EV\", \"EV\", \"MQ\", \"EV\", \"AA\", \"MQ\", \"EV\", \"…\n$ flight         &lt;int&gt; 181, 4633, 4462, 4555, 4255, 4621, 177, 4490, 3810, 9, …\n$ tailnum        &lt;chr&gt; \"N527JB\", \"N14974\", \"N11176\", \"N14148\", \"N645MQ\", \"N145…\n$ origin         &lt;chr&gt; \"JFK\", \"EWR\", \"LGA\", \"LGA\", \"JFK\", \"EWR\", \"JFK\", \"LGA\",…\n$ dest           &lt;chr&gt; \"SAN\", \"BTV\", \"CLE\", \"CLE\", \"BNA\", \"CVG\", \"SFO\", \"CMH\",…\n$ air_time       &lt;dbl&gt; 312, 47, 62, 73, 108, 92, 352, 80, 109, 135, 190, 138, …\n$ distance       &lt;dbl&gt; 2446, 266, 419, 419, 765, 569, 2586, 479, 708, 944, 159…\n$ hour           &lt;dbl&gt; 8, 11, 19, 6, 17, 17, 17, 8, 10, 17, 7, 6, 7, 11, 15, 8…\n$ minute         &lt;dbl&gt; 20, 10, 59, 10, 0, 29, 45, 15, 0, 36, 10, 59, 7, 15, 5,…\n$ time_hour      &lt;dttm&gt; 2013-01-04 08:00:00, 2013-12-05 11:00:00, 2013-08-19 1…\n\ncolnames(flights)# know the columns name of your dataset\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\n\n\n\n\nOnly the most used ones are covered below:\n\nint stands for integers (1,2,3).\ndbl stands for doubles, or real numbers (-1, 1.5,4/5).\nchr stands for character vectors, or strings (“this is a string”).\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values (freshman, sophomore, junior, senior).\nlgl stands for logical, vectors that contain only TRUE or FALSE (True, False, True).\ndate stands for dates (01/18/2021).\ndttm stands for date-times, a date + a time (01/18/2021 11:00 am).\n\n\n\n\nOnly the most used ones are covered below:\n\nVector: An atomic vector (or simply vector) is the simplest data structure in R which consists of an ordered set of values of the same type (e.g. numeric, character, date, etc…).\n\n\n\n\ndepartments &lt;- c(\"OMIS\", \"Finance\", \"Accounting\" , \"Management\",\"Marketing\")# a vector can be created using the combine function c()\n#departments\n\n\nstudents_number &lt;- c(220, 180, 255, 100, 170)#all the elements of a vector must have the same data type. This is why the data type determines the type of vector you have (e.g., numeric, characters, date vectors).\n#students_number\n\n\nstudents_avg_age &lt;- c(21.5, 22.1, 21.8, 21.3, 21.5)\n#students_avg_age\n\n\nDataframe/tibble/dataset: A dataframe is a data structure that organizes data into a 2-dimensional table of rows and columns, much like a spreadsheet. Dataframes are called tibbles in R (tidyverse).\n\nWe can create a tibble by combining two or more vectors of the same length.\n\n\n\n\ncob &lt;- tibble(departments,students_number,students_avg_age)# each vector was of 5 elements (or length 5) --&gt; this is why the cob dataframe has 5 rows. We are using three vectors in our cob dataframe --&gt; this is why we have 3 columns or variables. As you can see the vector name has become the column name and a tibble is not much different than an Excel spreadsheet\n#cob\n\nNOTE: there are other data structures available in R (e.g., matrices, lists etc.) but we will not use or cover them in this course.\nNow that you have a basic understanding of data types and structures (we will cover more about tibble next week) we can dive into useful functions for wrangling your data.\n\n\n\n\n\nPick observations based on their values (filter()).\nReorder the rows/columns (arrange()).\nPick variables based their column names (select()).\nCreate new variables or update existing variables (mutate()).\nCollapse many values down to a single summary (summarise()).\nAll the above functions can be used in conjunction with the function group_by() (our +1 function). group_by changes the scope of each function from operating on the entire dataset to operating on it group-by-group.\n\n\n\nThese six functions provide the verbs for a language of data manipulation. All verbs work similarly, and this is a great news, and have a similar structure:\nThe first argument is a dataframe on which you want to perform a manipulation.\nThe subsequent arguments describe what do you want to do with the original dataframe, using the variable names (without quotes).\nThe result is a new dataframe (remember to assign it to a new object if you want to preserve the changes). Together these properties make it easy to chain together multiple simple steps to achieve a complex result."
  },
  {
    "objectID": "chapter1.html#manipulations",
    "href": "chapter1.html#manipulations",
    "title": "Chapter 1: Manipulations",
    "section": "",
    "text": "When working on a new dataset the beginning might not be easy\n\n\nThe following sections of our book R for Data Science( first portion of the course book ) are included in the second week:\n\nData Transformation: Sections: from 3 to 3.3 & part of 3.5 included\n\n\n\n\nInternal help: posit support\nExternal help: stackoverflow\nAdditional materials: posit resources\nCheat Sheets: posit cheat sheets\n\nWhile I use the book as a reference the materials provided to you are custom made and include more activities and resources. If you understand the materials covered in this document there is no need to refer to other sources. If you have any troubles with the materials don’t hesitate to contact me or check the above sources.\n\n\n\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\n\n\n\nData Science model: Artwork by @allison_horst\n\n\n\n\n\n\nflights#dataset we will use --&gt; make sure you run library(nycflights13) before running this line of code\n\n# A tibble: 15,000 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     4      819            820        -1     1103           1129\n 2  2013    12     5     1238           1110        88     1342           1223\n 3  2013     8    19     1953           1959        -6     2141           2146\n 4  2013     4    14      608            610        -2      752            754\n 5  2013     4    29     1653           1700        -7     1815           1835\n 6  2013     4     5     1813           1729        44     2026           1937\n 7  2013     1    17     1740           1745        -5     2054           2120\n 8  2013     2    26      834            815        19     1031           1010\n 9  2013     2    20     1014           1000        14     1219           1221\n10  2013     3    22     1741           1736         5     2024           2029\n# ℹ 14,990 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n?flights # get a description of it\n#view(flights)# run this if you want to explore the entire dataset --&gt; which will open the dataset in the RStudio viewer.\nglimpse(flights)# run this if you want a summary of the dataset \n\nRows: 15,000\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 12, 8, 4, 4, 4, 1, 2, 2, 3, 1, 2, 12, 8, 7, 9, 9, 12…\n$ day            &lt;int&gt; 4, 5, 19, 14, 29, 5, 17, 26, 20, 22, 25, 18, 13, 5, 29,…\n$ dep_time       &lt;int&gt; 819, 1238, 1953, 608, 1653, 1813, 1740, 834, 1014, 1741…\n$ sched_dep_time &lt;int&gt; 820, 1110, 1959, 610, 1700, 1729, 1745, 815, 1000, 1736…\n$ dep_delay      &lt;dbl&gt; -1, 88, -6, -2, -7, 44, -5, 19, 14, 5, 4, -2, -5, -7, 1…\n$ arr_time       &lt;int&gt; 1103, 1342, 2141, 752, 1815, 2026, 2054, 1031, 1219, 20…\n$ sched_arr_time &lt;int&gt; 1129, 1223, 2146, 754, 1835, 1937, 2120, 1010, 1221, 20…\n$ arr_delay      &lt;dbl&gt; -26, 79, -5, -2, -20, 49, -26, 21, -2, -5, -4, -19, -9,…\n$ carrier        &lt;chr&gt; \"B6\", \"EV\", \"EV\", \"EV\", \"MQ\", \"EV\", \"AA\", \"MQ\", \"EV\", \"…\n$ flight         &lt;int&gt; 181, 4633, 4462, 4555, 4255, 4621, 177, 4490, 3810, 9, …\n$ tailnum        &lt;chr&gt; \"N527JB\", \"N14974\", \"N11176\", \"N14148\", \"N645MQ\", \"N145…\n$ origin         &lt;chr&gt; \"JFK\", \"EWR\", \"LGA\", \"LGA\", \"JFK\", \"EWR\", \"JFK\", \"LGA\",…\n$ dest           &lt;chr&gt; \"SAN\", \"BTV\", \"CLE\", \"CLE\", \"BNA\", \"CVG\", \"SFO\", \"CMH\",…\n$ air_time       &lt;dbl&gt; 312, 47, 62, 73, 108, 92, 352, 80, 109, 135, 190, 138, …\n$ distance       &lt;dbl&gt; 2446, 266, 419, 419, 765, 569, 2586, 479, 708, 944, 159…\n$ hour           &lt;dbl&gt; 8, 11, 19, 6, 17, 17, 17, 8, 10, 17, 7, 6, 7, 11, 15, 8…\n$ minute         &lt;dbl&gt; 20, 10, 59, 10, 0, 29, 45, 15, 0, 36, 10, 59, 7, 15, 5,…\n$ time_hour      &lt;dttm&gt; 2013-01-04 08:00:00, 2013-12-05 11:00:00, 2013-08-19 1…\n\ncolnames(flights)# know the columns name of your dataset\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\n\n\n\n\nOnly the most used ones are covered below:\n\nint stands for integers (1,2,3).\ndbl stands for doubles, or real numbers (-1, 1.5,4/5).\nchr stands for character vectors, or strings (“this is a string”).\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values (freshman, sophomore, junior, senior).\nlgl stands for logical, vectors that contain only TRUE or FALSE (True, False, True).\ndate stands for dates (01/18/2021).\ndttm stands for date-times, a date + a time (01/18/2021 11:00 am).\n\n\n\n\nOnly the most used ones are covered below:\n\nVector: An atomic vector (or simply vector) is the simplest data structure in R which consists of an ordered set of values of the same type (e.g. numeric, character, date, etc…).\n\n\n\n\ndepartments &lt;- c(\"OMIS\", \"Finance\", \"Accounting\" , \"Management\",\"Marketing\")# a vector can be created using the combine function c()\n#departments\n\n\nstudents_number &lt;- c(220, 180, 255, 100, 170)#all the elements of a vector must have the same data type. This is why the data type determines the type of vector you have (e.g., numeric, characters, date vectors).\n#students_number\n\n\nstudents_avg_age &lt;- c(21.5, 22.1, 21.8, 21.3, 21.5)\n#students_avg_age\n\n\nDataframe/tibble/dataset: A dataframe is a data structure that organizes data into a 2-dimensional table of rows and columns, much like a spreadsheet. Dataframes are called tibbles in R (tidyverse).\n\nWe can create a tibble by combining two or more vectors of the same length.\n\n\n\n\ncob &lt;- tibble(departments,students_number,students_avg_age)# each vector was of 5 elements (or length 5) --&gt; this is why the cob dataframe has 5 rows. We are using three vectors in our cob dataframe --&gt; this is why we have 3 columns or variables. As you can see the vector name has become the column name and a tibble is not much different than an Excel spreadsheet\n#cob\n\nNOTE: there are other data structures available in R (e.g., matrices, lists etc.) but we will not use or cover them in this course.\nNow that you have a basic understanding of data types and structures (we will cover more about tibble next week) we can dive into useful functions for wrangling your data.\n\n\n\n\n\nPick observations based on their values (filter()).\nReorder the rows/columns (arrange()).\nPick variables based their column names (select()).\nCreate new variables or update existing variables (mutate()).\nCollapse many values down to a single summary (summarise()).\nAll the above functions can be used in conjunction with the function group_by() (our +1 function). group_by changes the scope of each function from operating on the entire dataset to operating on it group-by-group.\n\n\n\nThese six functions provide the verbs for a language of data manipulation. All verbs work similarly, and this is a great news, and have a similar structure:\nThe first argument is a dataframe on which you want to perform a manipulation.\nThe subsequent arguments describe what do you want to do with the original dataframe, using the variable names (without quotes).\nThe result is a new dataframe (remember to assign it to a new object if you want to preserve the changes). Together these properties make it easy to chain together multiple simple steps to achieve a complex result."
  },
  {
    "objectID": "chapter1.html#filter",
    "href": "chapter1.html#filter",
    "title": "Chapter 1: Manipulations",
    "section": "Filter()",
    "text": "Filter()\nfilter() is used to include in your dataset only observations that meet one or more logical conditions. For example, you will use filter if from an imaginary US tax payers dataset (tax_payers), you want to continue your analysis only on tax payers that live in Illinois given a states variable (notice that by doing so # of observations/rows decreases while # of variables/columns stays the same). –&gt; filter(tax_payers, state== “IL”)\n\n#Example: flights that traveled on January (Note the # of observation included in the dataset)\nfilter(#the results do not replace the original dataset. To save it to future analysis assign it to a new variable named jan_flights. Create the variable jan_flights \n #&lt;- \n# print jan_flights\n#Example 2: flights that traveled to Ohare (ORD)\n\nError: &lt;text&gt;:7:0: unexpected end of input\n5: #Example 2: flights that traveled to Ohare (ORD)\n6: \n  ^\n\n\nTo use filtering effectively, you have to know how to select the observations that you want using the comparison operators. R provides the standard suite: &gt;, &gt;=, &lt;, &lt;=, != (not equal), and == (equal).\nWhen you’re starting out with R, the easiest mistake to make is to use = instead of == when testing for equality. When this happens you’ll get an informative error:\n\nfilter(flights, month = 1)\n\nError in `filter()`:\n! We detected a named input.\nℹ This usually means that you've used `=` instead of `==`.\nℹ Did you mean `month == 1`?\n\n\nMultiple arguments to filter() are combined with “and”: every expression must be true in order for a row to be included in the output. For other types of combinations, you’ll need to use Boolean operators yourself: & is “and”, | is “or”, and ! is “not”. The “,” can also be used instead of &. However, I do recommend to use & especially at the beginning as it is easier for you to remind that both conditions must be met for an observation to be included in the analysis. However, if you combine an “&” and “|” in the same filter you need parenthesis to separate the “&” and the “|” (see below note).\n\n#Example 3: find flights in November and December\nfilter(# look at the results. Does it make sense to have such filter?\n\n#Example 4: find flights in November or December\nfilter(# Now this makes sense as you want to constraint the focus of your analysis to the last two months of the year. You might have an intuition that during the holiday season there is need for more flights/personnel \n\n# Example 5: find flights that weren’t delayed (on arrival or departure) by more than two hours \nfilter(# Hours are presented in minutes in the dataset that's why 120. Again, you need to get to know your data before starting manipulations. If you don't remember column names check the colnames function (?colnames).\n\nError: &lt;text&gt;:10:0: unexpected end of input\n8: filter(# Hours are presented in minutes in the dataset that's why 120. Again, you need to get to know your data before starting manipulations. If you don't remember column names check the coln\n9: \n  ^\n\n\n\nActivity 1: Filter\n\n#flights in january with more than 60 minutes delay\n\n\n#flights with departure or arrival delay smaller than 15 minutes\n\n\n#flights with distance equal or bigger than 1010 miles\n\n\n#flights operated by american airlines (AA)\n\n\nNOTE\nBe careful in using & and , as substitutes. In some cases they are but in other not. For example if you are looking for the flights in January with more than 60 minutes delay both in departure and arrival\n\nfilter(flights, month==1 & dep_delay&gt; 60 & arr_delay&gt;60)\n\n# A tibble: 80 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1    31     2029           1900        89     2151           2018\n 2  2013     1    31     2051           1750       181     2217           1908\n 3  2013     1    30     2322           2000       202      129           2224\n 4  2013     1     2     2148           2004       104     2234           2112\n 5  2013     1    25     2051           1910       101        8           2215\n 6  2013     1    31     2130           2000        90     2235           2114\n 7  2013     1    23      836            655       101     1049            927\n 8  2013     1    23     1949           1745       124     2226           2020\n 9  2013     1     4     1430           1240       110     1717           1540\n10  2013     1    16     1741           1530       131     1933           1711\n# ℹ 70 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nthis line is equivalent to the one below with ,.\n\nfilter(flights, month==1 , dep_delay&gt; 60 , arr_delay&gt;60)\n\n# A tibble: 80 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1    31     2029           1900        89     2151           2018\n 2  2013     1    31     2051           1750       181     2217           1908\n 3  2013     1    30     2322           2000       202      129           2224\n 4  2013     1     2     2148           2004       104     2234           2112\n 5  2013     1    25     2051           1910       101        8           2215\n 6  2013     1    31     2130           2000        90     2235           2114\n 7  2013     1    23      836            655       101     1049            927\n 8  2013     1    23     1949           1745       124     2226           2020\n 9  2013     1     4     1430           1240       110     1717           1540\n10  2013     1    16     1741           1530       131     1933           1711\n# ℹ 70 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nIn this case & and , are perfect substitutes but it is not always the case. Let’s check the example below:\n\nfilter(flights, month==1 & dep_delay&gt; 60 |arr_delay&gt;60)\n\n# A tibble: 1,278 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013    12     5     1238           1110        88     1342           1223\n 2  2013    12    18     1704           1509       115     1933           1742\n 3  2013     9    20     1506           1345        81     1635           1523\n 4  2013     5    20     1105           1003        62     1314           1212\n 5  2013     7     7      721            600        81      822            715\n 6  2013     5     3     1413           1200       133     1554           1338\n 7  2013     7    27     1432           1315        77     1614           1505\n 8  2013     1    31     1934           1855        39     2333           2210\n 9  2013    12    27     2315           2219        56      408            304\n10  2013     7     2     2034           1930        64        5           2248\n# ℹ 1,268 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nfilter(flights, month==1 , dep_delay&gt; 60 |arr_delay&gt;60)\n\n# A tibble: 100 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1    31     1934           1855        39     2333           2210\n 2  2013     1    31     2029           1900        89     2151           2018\n 3  2013     1    31     2051           1750       181     2217           1908\n 4  2013     1    31     1040           1000        40     1419           1310\n 5  2013     1    30     2322           2000       202      129           2224\n 6  2013     1     2     2148           2004       104     2234           2112\n 7  2013     1    25     2051           1910       101        8           2215\n 8  2013     1    31     2130           2000        90     2235           2114\n 9  2013     1    23      836            655       101     1049            927\n10  2013     1    23     1949           1745       124     2226           2020\n# ℹ 90 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nIn fact, the | is affecting the equivalency with the ,. So, if in your filter you have both a & and |, the & and the , are not equivalent.\nTo achieve equality in this case, you need parenthesis to divide the & and | conditions.\n\nfilter(flights, month==1 & (dep_delay&gt; 60 |arr_delay&gt;60))\n\n# A tibble: 100 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1    31     1934           1855        39     2333           2210\n 2  2013     1    31     2029           1900        89     2151           2018\n 3  2013     1    31     2051           1750       181     2217           1908\n 4  2013     1    31     1040           1000        40     1419           1310\n 5  2013     1    30     2322           2000       202      129           2224\n 6  2013     1     2     2148           2004       104     2234           2112\n 7  2013     1    25     2051           1910       101        8           2215\n 8  2013     1    31     2130           2000        90     2235           2114\n 9  2013     1    23      836            655       101     1049            927\n10  2013     1    23     1949           1745       124     2226           2020\n# ℹ 90 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nWithout the parenthesis you will get different & wrong results as above. So, please be careful and keep this in mind."
  },
  {
    "objectID": "chapter1.html#arrange",
    "href": "chapter1.html#arrange",
    "title": "Chapter 1: Manipulations",
    "section": "Arrange()",
    "text": "Arrange()\narrange() works similarly to filter() except that instead of selecting rows, it changes the order in which they are presented in the dataset. For example, using the above US tax payers dataset, you will use arrange if you want to sort the dataset by the tax payers last name in decreasing order (Z-A). –&gt; arrange(tax_payers, desc(last_name)) Arrange takes a dataframe and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of preceding columns:\n\narrange(flights, year, month, day)\n\n# A tibble: 15,000 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1     1044           1041         3     1339           1350\n 2  2013     1     1     1730           1730         0     2013           1959\n 3  2013     1     1      723            725        -2     1013           1017\n 4  2013     1     1      732            729         3     1041           1039\n 5  2013     1     1      752            759        -7      955            959\n 6  2013     1     1     1240           1229        11     1451           1428\n 7  2013     1     1      600            600         0      851            858\n 8  2013     1     1     1744           1720        24     2052           2025\n 9  2013     1     1     1653           1700        -7     2005           2018\n10  2013     1     1     1649           1639        10     1937           1911\n# ℹ 14,990 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n#arrange(flights, desc(dep_delay))#desc allows to re-order by a column in descending order\n# Example 1: arrange the dataset based on destination increasing alphabetical order\n\n#Example 2: arrange the dataset based on distance decreasing order\n\n\nActivity 2: Arrange\n\n#flights by distance from smaller to bigger\n\n\n#flights by air time\n\n\n#flights with distance equal or bigger than 1010 miles\n\n\n#flights by arr_delay from bigger to smaller"
  },
  {
    "objectID": "chapter1.html#select",
    "href": "chapter1.html#select",
    "title": "Chapter 1: Manipulations",
    "section": "Select()",
    "text": "Select()\nselect() allows you to continue the analysis only on some specific columns of your original dataset. By using select you can rapidly zoom in on a useful subset of variables that you think needs deeper investigation or that are part of the scope of your analysis. For example, using the same imaginary US tax payer dataset, you want to focus your analysis on just salary, gender and age. It is unnecessary to keep all the other columns as you already know that they are not going to be included in the scope of the analysis –&gt; select(tax_payers, salary, gender, age)\n\nselect(flights, year, month, day)#Select columns by name\n\n# A tibble: 15,000 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     4\n 2  2013    12     5\n 3  2013     8    19\n 4  2013     4    14\n 5  2013     4    29\n 6  2013     4     5\n 7  2013     1    17\n 8  2013     2    26\n 9  2013     2    20\n10  2013     3    22\n# ℹ 14,990 more rows\n\nselect(flights, year:day)#Select all columns between year and day (inclusive)\n\n# A tibble: 15,000 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     4\n 2  2013    12     5\n 3  2013     8    19\n 4  2013     4    14\n 5  2013     4    29\n 6  2013     4     5\n 7  2013     1    17\n 8  2013     2    26\n 9  2013     2    20\n10  2013     3    22\n# ℹ 14,990 more rows\n\nselect(flights, 1:3)#Select columns based on their position in the dataset (inclusive)\n\n# A tibble: 15,000 × 3\n    year month   day\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     4\n 2  2013    12     5\n 3  2013     8    19\n 4  2013     4    14\n 5  2013     4    29\n 6  2013     4     5\n 7  2013     1    17\n 8  2013     2    26\n 9  2013     2    20\n10  2013     3    22\n# ℹ 14,990 more rows\n\nselect(flights, -(year:day))# Select all columns except those from year to day (inclusive)\n\n# A tibble: 15,000 × 16\n   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay carrier\n      &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;  \n 1      819            820        -1     1103           1129       -26 B6     \n 2     1238           1110        88     1342           1223        79 EV     \n 3     1953           1959        -6     2141           2146        -5 EV     \n 4      608            610        -2      752            754        -2 EV     \n 5     1653           1700        -7     1815           1835       -20 MQ     \n 6     1813           1729        44     2026           1937        49 EV     \n 7     1740           1745        -5     2054           2120       -26 AA     \n 8      834            815        19     1031           1010        21 MQ     \n 9     1014           1000        14     1219           1221        -2 EV     \n10     1741           1736         5     2024           2029        -5 B6     \n# ℹ 14,990 more rows\n# ℹ 9 more variables: flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;,\n#   air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n# Example 1: select the 2nd, 4th and 10th columns \n\n#Example 2: select all the columns but the last 3\n\nAs you can see there are multiple ways to select the same columns (first 3 lines of code give the same outcome: year, month , day subset), but not all of them have the same efficiency. Imagine selecting the first 15 column using the first line of code (you will have to manually type 15 columns name) compared to using the second line (first column : fifteenth column) or the third (1:15). However, when you use the last two methods I recommend to check the column order using the function colnames()\nMoreover, there are a number of helper functions you can use within select():\nstarts_with(“abc”): matches names that begin with “abc”.\nends_with(“xyz”): matches names that end with “xyz”.\ncontains(“ijk”): matches names that contain “ijk”.\nSee ?select for more details.\n\nActivity 3: Select\n\n#first 10 adjacent columns\n\n\n#columns that contain the word \"time\"\n\n\n#all columns but those that contain the word \"time\"\n\n\n#columns that start with the letter \"d\""
  },
  {
    "objectID": "chapter1.html#mutate",
    "href": "chapter1.html#mutate",
    "title": "Chapter 1: Manipulations",
    "section": "Mutate()",
    "text": "Mutate()\nmutate() enables you to change the columns available in your original dataset. By using mutate() you can add new columns that are functions of existing columns. For example, in the tax_payers dataset, you note that the salary column is reported in euros rather than dollars. In this case, you want to create a new column that reports salary in euros. To do so you need to multiple the value that are in the original salary by the conversion rate between euros and dollars. –&gt; mutate(tax_payers, salary_USD = salary * 1.21). Note how I chose a meaningful name for the new column, and that the conversion rate at the time I created this rmd file was 1.21.\nMoreover, keep in mind that mutate() always adds new columns at the end of your dataset. So, to view the new column you can use View(tax_payers) or select(tax_payers, salary_USD). Nonetheless, If you want to just use the new compute column you can also use the transmute() function (see example below).\n\nflights_sml &lt;- select(flights, \n  year:day, \n  ends_with(\"delay\"), \n  distance, \n  air_time\n)# what is the purpose of running this?\n\n\n# Example 1: using the flights_sml dataset compute a column named gain equal to the difference between departure delay and arrival delay\nmutate(\n  \n# Example 2: using the flights_sml dataset compute a column named gain equal to the difference between departure delay and arrival delay; a column named hours equal to air time dived by 60; and a column named gain_per_hour equal to gain divided by hours.\nmutate( # you can refer to column your are just creating, be careful to the order. Can you invert the order of gain_per_hour and gain. Let's try!\n\n# Example 3: using the flights_sml dataset  compute a column named speed equal to the variable distance divided by air time multiplied by 60 (we want speed in mph). Use transmute instead of mutate. What is the difference?\ntransmute(#If you only want to keep the new variables, use transmute()\n\nError: &lt;text&gt;:10:0: unexpected end of input\n8: transmute(#If you only want to keep the new variables, use transmute()\n9: \n  ^\n\n\n\nActivity 4: Mutate\n\n#compute a variable that shows the difference between scheduled departure time and the actual time of departure\n\n\n#compute a variable that shows the air time divided by the total flight distance\n\n\n#compute a variable that shows the difference between scheduled arrival time and the actual time of arrival\n\n\n##compute a variable that shows the sum of the departure delay and the air time"
  },
  {
    "objectID": "chapter1.html#summarise",
    "href": "chapter1.html#summarise",
    "title": "Chapter 1: Manipulations",
    "section": "Summarise()",
    "text": "Summarise()\nsummarise() enables you to compute descriptive statistics of your dataset. summarise() collapses a dataframe to a single row. For example, if you want to compute the average salary of the observation of the tax payers in your dataset, summarise will return to you one row that contains the average value. –&gt; summarise(tax_payers, avg_salary = mean(salary)). Note how I chose a meaningful name for the output of my summary.\n\nsummarise(flights, avg_delay = mean(dep_delay, na.rm = TRUE))# we will talk later about NAs (missing values) but the na.rm=TRUE argument is critical if the column you are using for your average contains missing values. Let's remove that argument amd see what happens.\n\n# A tibble: 1 × 1\n  avg_delay\n      &lt;dbl&gt;\n1      13.1\n\n\n\n# Example 1: compute the mean of the arrival delay column\n\n# Example 2: find the max distance\n\nsummarise() is not terribly useful unless we pair it with group_by() or better it is pretty limited to summarise a single value per column. For example, imagine that you want to see how the average salary of tax payers change depending on their age. In this case, you need to first group_by your dataset using the age column and then compute the average salary. Thanks to the combination of group_by and summarise you will able to explore if the average salary of a 40 years old tax payer is on average higher/lower or equal to the ones of a 21 years old tax payer."
  },
  {
    "objectID": "chapter1.html#summarise-group_by",
    "href": "chapter1.html#summarise-group_by",
    "title": "Chapter 1: Manipulations",
    "section": "Summarise + group_by()",
    "text": "Summarise + group_by()\nSo, when you use the group_by() function you can change the unit of analysis from the complete dataset to individual groups (columns that caught your attention). group_by will create a group for each unique value available in the selected column.Then, when you use the dplyr verbs on a grouped dataframe they’ll be automatically applied “by group”. For example, if we applied exactly the same code to a dataframe grouped by date, we get the average delay per date:\n\nby_day &lt;- group_by(flights, year, month, day)\nsummarise(by_day, avg_delay_date = mean(dep_delay, na.rm = TRUE))#help in answer the question about how dates are affecting the delay\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day avg_delay_date\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;          &lt;dbl&gt;\n 1  2013     1     1         16.7  \n 2  2013     1     2          6.53 \n 3  2013     1     3         16.4  \n 4  2013     1     4         22.5  \n 5  2013     1     5          1.15 \n 6  2013     1     6          4.42 \n 7  2013     1     7          4.75 \n 8  2013     1     8          3.49 \n 9  2013     1     9          0.432\n10  2013     1    10          0.396\n# ℹ 355 more rows\n\n\n\n#Example 1: do the same analysis for each airlines. Call the column avg_dalay_carrier.\nby_carrier\nsummarise(#help in answer the question about how the airlines are affecting the delay\n\nError: &lt;text&gt;:4:0: unexpected end of input\n2: by_carrier\n3: summarise(#help in answer the question about how the airlines are affecting the delay\n  ^\n\n\nTogether group_by() and summarise() provide one of the tools that you’ll use most commonly when working with dplyr: grouped summaries. These two functions are extremely useful to create descriptives statistics of the column of your dataset.\n\nActivity 5: Summarise\n\n#compute the max dep_delay\n\n\n#compute the min air_time\n\n\n#compute mean and standard deviation of the distance per each destination\n\n\n#compute the max and min of air_time per each month\n\n\n\nData Inside R\n\n#Running this code is the equivalent of simply running the name of the dataset you want to print. Meaning default printing will be applied\nflights# but what if I want to print in console all columns?\n\n# A tibble: 15,000 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     4      819            820        -1     1103           1129\n 2  2013    12     5     1238           1110        88     1342           1223\n 3  2013     8    19     1953           1959        -6     2141           2146\n 4  2013     4    14      608            610        -2      752            754\n 5  2013     4    29     1653           1700        -7     1815           1835\n 6  2013     4     5     1813           1729        44     2026           1937\n 7  2013     1    17     1740           1745        -5     2054           2120\n 8  2013     2    26      834            815        19     1031           1010\n 9  2013     2    20     1014           1000        14     1219           1221\n10  2013     3    22     1741           1736         5     2024           2029\n# ℹ 14,990 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n?flights#get info about the dataset\ncolnames(flights)#get the columns in the dataset\n\n [1] \"year\"           \"month\"          \"day\"            \"dep_time\"      \n [5] \"sched_dep_time\" \"dep_delay\"      \"arr_time\"       \"sched_arr_time\"\n [9] \"arr_delay\"      \"carrier\"        \"flight\"         \"tailnum\"       \n[13] \"origin\"         \"dest\"           \"air_time\"       \"distance\"      \n[17] \"hour\"           \"minute\"         \"time_hour\"     \n\nglimpse(flights)#useful way to collapse the content in a summary format\n\nRows: 15,000\nColumns: 19\n$ year           &lt;int&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2…\n$ month          &lt;int&gt; 1, 12, 8, 4, 4, 4, 1, 2, 2, 3, 1, 2, 12, 8, 7, 9, 9, 12…\n$ day            &lt;int&gt; 4, 5, 19, 14, 29, 5, 17, 26, 20, 22, 25, 18, 13, 5, 29,…\n$ dep_time       &lt;int&gt; 819, 1238, 1953, 608, 1653, 1813, 1740, 834, 1014, 1741…\n$ sched_dep_time &lt;int&gt; 820, 1110, 1959, 610, 1700, 1729, 1745, 815, 1000, 1736…\n$ dep_delay      &lt;dbl&gt; -1, 88, -6, -2, -7, 44, -5, 19, 14, 5, 4, -2, -5, -7, 1…\n$ arr_time       &lt;int&gt; 1103, 1342, 2141, 752, 1815, 2026, 2054, 1031, 1219, 20…\n$ sched_arr_time &lt;int&gt; 1129, 1223, 2146, 754, 1835, 1937, 2120, 1010, 1221, 20…\n$ arr_delay      &lt;dbl&gt; -26, 79, -5, -2, -20, 49, -26, 21, -2, -5, -4, -19, -9,…\n$ carrier        &lt;chr&gt; \"B6\", \"EV\", \"EV\", \"EV\", \"MQ\", \"EV\", \"AA\", \"MQ\", \"EV\", \"…\n$ flight         &lt;int&gt; 181, 4633, 4462, 4555, 4255, 4621, 177, 4490, 3810, 9, …\n$ tailnum        &lt;chr&gt; \"N527JB\", \"N14974\", \"N11176\", \"N14148\", \"N645MQ\", \"N145…\n$ origin         &lt;chr&gt; \"JFK\", \"EWR\", \"LGA\", \"LGA\", \"JFK\", \"EWR\", \"JFK\", \"LGA\",…\n$ dest           &lt;chr&gt; \"SAN\", \"BTV\", \"CLE\", \"CLE\", \"BNA\", \"CVG\", \"SFO\", \"CMH\",…\n$ air_time       &lt;dbl&gt; 312, 47, 62, 73, 108, 92, 352, 80, 109, 135, 190, 138, …\n$ distance       &lt;dbl&gt; 2446, 266, 419, 419, 765, 569, 2586, 479, 708, 944, 159…\n$ hour           &lt;dbl&gt; 8, 11, 19, 6, 17, 17, 17, 8, 10, 17, 7, 6, 7, 11, 15, 8…\n$ minute         &lt;dbl&gt; 20, 10, 59, 10, 0, 29, 45, 15, 0, 36, 10, 59, 7, 15, 5,…\n$ time_hour      &lt;dttm&gt; 2013-01-04 08:00:00, 2013-12-05 11:00:00, 2013-08-19 1…\n\nflights |&gt; \n  view()# the other option to print more rows and actually all rows is still the view () function discussed in week 1 to open the dataset in a new window\n\n# \" |&gt; \" # is the pipe operator and it is used to combine functions and apply them to variables within the tidyverse package. The shortcut for the pipe operator is cmd/ctrl + shift+ M. More of its application later in the class.\n\n\n\nImporting data\nBut what happen when your data come from outside of R? It is time to learn how to import external data. To load flat files in R we will use the readr package, which is part of the core tidyverse package. Most of readr’s functions are concerned with turning flat files into dataframes (e.g, csv files but similar functions exist also for Excel files or other delimited files). These functions all have similar syntax: once you’ve mastered one, you can use the others with ease. In this course we’ll focus on read_csv(). Not only are csv files one of the most common forms of data storage, but once you understand read_csv(), you can easily apply your knowledge to all the other functions in readr.\nThe first argument to read_csv() is the most important: it’s the path to the file to read. Once again if your file is in your project folder, you will not have any troubles to access it:\n\nheights &lt;- read_csv(\"heights.csv\")#When you run read_csv() it prints out a column specification that gives the name and type of each column. #the heights.csv is available for download on Blackboard in the week 3 module. If this code doesn't work, make sure to move the file in your project folder.\n\nError: 'heights.csv' does not exist in current working directory ('C:/Users/venka/OneDrive - Northern Illinois University/Desktop/Vineel/Vineel/TA work/Fall_2024/Code Base/omis482-f2024-class-website').\n\n\n\nNOTE\nread_csv() uses the first line of the data for the column names, which is a very common convention. The data might not have column names. You can use col_names = FALSE to tell read_csv() not to treat the first row as headings, and instead label them sequentially from X1 to Xn. The function will guess the data type of each column by looking at the first 1000 rows. It is your responsibility to make sure that the columns type are correct. For more info look the parsing sections 11.3 and 11.4. To get other types of data into R, I recommend starting with the tidyverse packages listed below:\n\nhaven package: reads SPSS, Stata, and SAS files.\nreadxl package: reads excel files (both .xls and .xlsx).\nDBI package: along with a database specific backend (e.g. RMySQL, RSQLite, RPostgreSQL etc) allows you to run SQL queries against a database and return a data frame.\n\n\n\n\nWriting data\nNow that we have seen how to bring data into RStudio, what about exporting data from RStudio? The readr package comes also with two useful functions for writing data back to disk: write_csv() and write_tsv(). If you want to export a csv file to Excel, use write_excel_csv(). The most important arguments are x (the data frame to save), and path (the location to save it).\n\nwrite_csv(nycflights13::flights, \"flights.csv\")#I am exporting the flights dataset and writing it into a csv file called flights.csv. After running the code that file will be available in your working directory (which should be your project folder)"
  },
  {
    "objectID": "chapter1.html#pipes",
    "href": "chapter1.html#pipes",
    "title": "Chapter 1: Manipulations",
    "section": "Pipes",
    "text": "Pipes\nYou probably have seen the pipe symbol before but let’s learn how it works and why it is so important in tidyverse. Before we do that please keep in mind that two types of pipes exist:\n\nThe magrittr pipe %&gt;% that comes from the magrittr package created by Stefan Milton Bache. Packages in the tidyverse load %&gt;% for you automatically, so you don’t usually load magrittr explicitly. While magrittr pipe was used for a while in the tidyverse world, it is now losing its traction.\nIn fact, the native pipe |&gt; is becoming more popular and it is most commonly used.\n\nFor this course we will use only the native pipe |&gt;. While for simple cases, |&gt; and %&gt;% behave identically only the native pipe is part of base R, and so it’s always available for you to use, even when you’re not loading the tidyverse. Moreover, |&gt; is simpler than %&gt;% and it works better with more advanced tasks.\nHowever, you might need to make one change to your RStudio options to use |&gt; instead of %&gt;% by accessing the Code Editing tab of your Project Option; After you made this change you can add the native pipe to your code by using the built-in keyboard shortcut Ctrl/Cmd + Shift + M.\n\nCombining multiple operations with the pipe\nImagine that we want to explore the relationship between the distance and average delay for each destination. There are three steps to prepare our original flights data:\n\nGroup flights by destination.\nSummarise to compute average distance, average delay, and number of flights.\nFilter to remove noisy points (less than 20 observations, small sample) and Honolulu airport (almost twice as far away as the next closest airport).\n\nIf we put in practice what we learned so far, this code is a little frustrating to write because we have to give each intermediate data frame a name, even though we don’t care about it. Naming things is hard, so this slows down our analysis.\n\nby_dest &lt;- group_by(flights, dest)\n\n\ndelay &lt;- summarise(by_dest,\n  count = n(),\n  avg_dist = mean(distance, na.rm = TRUE),\n  avg_delay = mean(arr_delay, na.rm = TRUE)\n)#know how many flights go to each destination [n()]; average distance and average delay for flights at each destination\n\n\ndelay_filtered &lt;- filter(delay, count &gt; 20, dest != \"HNL\")#now let's remove all destinations that have less or equal to 20 flights and let's exclude Honululu from it. Notice how many assignment I need to create the desired object (3)\n\nThere’s another, much simpler and efficient, way to tackle the same problem thanks to the pipe operator, |&gt;, because we can combine manipulations together:\n\nfiltered_delay &lt;- flights |&gt; \n  group_by(dest) |&gt; \n  summarise(\n    count = n(),\n    avg_dist = mean(distance, na.rm = TRUE),\n    avg_delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt; \n  filter(count &gt; 20, dest != \"HNL\") #Notice how many assignment I need to create the desired object (1), two less than the previous code.\n\nAnyway, what is great about using pipe is that your code now focuses on the transformations, and not anymore on what’s being transformed, which makes the code easier to read. In fact, the best way to read the above code is to take each line before the pipe as an imperative statement (remember that the dataset us always the starting point). - Take the flights dataset, then - Group it by destination, then - summarise it (I want the number of flights at each destination, the average distance and the average delay of each destination), then - Filter the results and include only those destinations with more than 20 flights and exclude Honululu.\nAs suggested by this reading, a good way to pronounce |&gt; when reading code is “then”. So, remember that you can use the pipe to rewrite multiple operations in a way that you can read left-to-right, top-to-bottom. We’ll use piping from now on because it considerably improves the readability of code and it makes your code more efficient. Working with the pipe is one of the key criteria for belonging to the tidyverse world!\nBy the way we can use the pipe also to what we have already learned ;-)\n\n\nActivity 6: Basic pipes\n\n# keep only the flights in February with more than 75 minutes delay\n\n\n# sort the flights by air_time from bigger to smaller\n\n\n# keep all columns but those that contain the word \"dep\"\n\n\n# compute a column named gain equal to the difference between departure delay and arrival delay\n\n\n\nMissing values\nOk now it is time to provide an explanation on the na.rm argument that we used in the summarise function. Let’s try one more time in not using it. What happens if we don’t have it?\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarise(mean = mean(dep_delay))\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day   mean\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n 1  2013     1     1 16.7  \n 2  2013     1     2 NA    \n 3  2013     1     3 16.4  \n 4  2013     1     4 22.5  \n 5  2013     1     5  1.15 \n 6  2013     1     6  4.42 \n 7  2013     1     7  4.75 \n 8  2013     1     8  3.49 \n 9  2013     1     9  0.432\n10  2013     1    10 NA    \n# ℹ 355 more rows\n\n\nWe get a lot of missing values! That’s because aggregation functions obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. Fortunately, all aggregation functions have an na.rm argument which removes the missing values prior to computation:\n\nflights |&gt; \n  group_by(year, month, day) |&gt; \n  summarise(mean = mean(dep_delay, na.rm = TRUE))\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day   mean\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n 1  2013     1     1 16.7  \n 2  2013     1     2  6.53 \n 3  2013     1     3 16.4  \n 4  2013     1     4 22.5  \n 5  2013     1     5  1.15 \n 6  2013     1     6  4.42 \n 7  2013     1     7  4.75 \n 8  2013     1     8  3.49 \n 9  2013     1     9  0.432\n10  2013     1    10  0.396\n# ℹ 355 more rows\n\n\nIn this case, missing values represent cancelled flights. So, we could also tackle the problem by first removing all the cancelled flights. By doing so we get rid of all missing values and so of the need of using the na.rm argument.\n\nnot_cancelled &lt;- flights |&gt; \n  filter(!is.na(dep_delay), !is.na(arr_delay))#save this dataset so we can reuse it in the future.\n\n\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarise(mean = mean(dep_delay))#no need of na.rm since we don't have NAs anymore\n\n# A tibble: 365 × 4\n# Groups:   year, month [12]\n    year month   day   mean\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;\n 1  2013     1     1 16.7  \n 2  2013     1     2  6.53 \n 3  2013     1     3 16.4  \n 4  2013     1     4 22.5  \n 5  2013     1     5  1.15 \n 6  2013     1     6  4.42 \n 7  2013     1     7  4.75 \n 8  2013     1     8  3.49 \n 9  2013     1     9  0.432\n10  2013     1    10  0.396\n# ℹ 355 more rows\n\n\n\n\nWhy producing counts matters?\nWe have already seen how to count observations. However, it is extremely important that you keep in mind that whenever you do any aggregation, it’s always a good idea to include either a count (n()), or a count of non-missing values (sum(!is.na(x))). That way you can check that you’re not drawing conclusions based on very small amounts of data. Results and conclusions based on few observations contain noise and are drawn based on a small number of events and can lead to incorrect insights.\nImaginary Scenario: Let’s talk about flight delays and why we can’t always compare them from different times like before, during, and after the pandemic. Things change, and comparisons might not be fair.\nImagine a new direct flight from DeKalb to Potenza. On its first trip, something rare happens: a passenger gets sick, and because of a new rule, the flight is delayed for 14 hours while they wait for a health check.\nIf we only look at this one flight, we might think the average delay for this route is 14 hours. But that’s not true, it’s just one unusual case. We can’t say all flights on this route are always delayed like this based on one incident. We need more flights to make a fair judgment. If after many flights the delay is still long, then we might think it’s a bad route. But for now, it’s too early to decide based on just one flight.\nI hope the scenario made the point on the importance of count clear. Now let’s use a real data example and let’s look at the planes (identified by their tail number) that have the highest average delays:\n\nnot_cancelled |&gt; \n  group_by(tailnum) |&gt; \n  summarise(\n    delay = mean(dep_delay))# no info about how many flights each tailnum has made. Which one seem the most problematic? \n\n# A tibble: 3,088 × 2\n   tailnum delay\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 N0EGMQ   3.81\n 2 N10156  54   \n 3 N102UW  -1   \n 4 N103US   0   \n 5 N104UW  28.7 \n 6 N10575  30   \n 7 N105UW  -8   \n 8 N107US  -2.5 \n 9 N108UW  -3   \n10 N110UW  -3   \n# ℹ 3,078 more rows\n\n\n\nnot_cancelled |&gt; \n  group_by(tailnum) |&gt; \n  summarise(\n    delay = mean(dep_delay, na.rm = TRUE), n = n())#now you also now on how many flights your average is based on. You don't want to base any conclusion on a small number of observation. Check the # of flights for the tail number D942DN\n\n# A tibble: 3,088 × 3\n   tailnum delay     n\n   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;\n 1 N0EGMQ   3.81    16\n 2 N10156  54        4\n 3 N102UW  -1        1\n 4 N103US   0        2\n 5 N104UW  28.7      3\n 6 N10575  30       19\n 7 N105UW  -8        1\n 8 N107US  -2.5      2\n 9 N108UW  -3        3\n10 N110UW  -3        1\n# ℹ 3,078 more rows\n\n\n\n\nRecap of the summary functions\nJust using means and counts can get you a long way, but R provides many other useful summary functions that should be taken in consideration when producing descriptive statistics. Here is a list of the most useful ones with many opportunities to practice them in the activities belpw:\n\nMeasures of location: mean(x) and median(x) . The mean is the sum divided by the length; the median is a value where 50% of x is above it, and 50% is below it.\nMeasures of spread: sd(x). The root mean squared deviation, or standard deviation sd(x), is the standard measure of spread.\nMeasures of rank: min(x) and max(x). The min will help you identify the smallest value, while the max allows you to find the largest value in column.\n\n\n#measures of location example\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarise(\n    avg_delay = mean(dep_delay),\n    median_delay = median(dep_delay)) # the average positive delay\n\n# A tibble: 365 × 5\n# Groups:   year, month [12]\n    year month   day avg_delay median_delay\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1  2013     1     1    16.7              0\n 2  2013     1     2     6.53            -1\n 3  2013     1     3    16.4              0\n 4  2013     1     4    22.5              1\n 5  2013     1     5     1.15            -2\n 6  2013     1     6     4.42            -3\n 7  2013     1     7     4.75            -2\n 8  2013     1     8     3.49            -2\n 9  2013     1     9     0.432           -4\n10  2013     1    10     0.396           -4\n# ℹ 355 more rows\n\n\n\n#measures of spread example\nnot_cancelled |&gt; \n  group_by(dest) |&gt; \n  summarise(distance_sd = sd(distance)) |&gt; \n  arrange(desc(distance_sd))# Is distance to some destinations more variable than to others?\n\n# A tibble: 99 × 2\n   dest  distance_sd\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 HNL         10.2 \n 2 LAS         10.2 \n 3 PDX         10.1 \n 4 SFO          9.99\n 5 SAN          9.98\n 6 PHX          9.88\n 7 SEA          9.86\n 8 EGE          9.61\n 9 LAX          9.56\n10 CVG          9.17\n# ℹ 89 more rows\n\n\n\n#measures of rank example\nnot_cancelled |&gt; \n  group_by(year, month, day) |&gt; \n  summarise(\n    first = min(dep_time),\n    last = max(dep_time)\n  )# When do the first and last flights leave each day?\n\n# A tibble: 365 × 5\n# Groups:   year, month [12]\n    year month   day first  last\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1  2013     1     1   600  2052\n 2  2013     1     2   558  2215\n 3  2013     1     3   600  2140\n 4  2013     1     4   106  2158\n 5  2013     1     5   555  2204\n 6  2013     1     6   559  2353\n 7  2013     1     7   559  2052\n 8  2013     1     8   623  2119\n 9  2013     1     9   603  2056\n10  2013     1    10   618  2129\n# ℹ 355 more rows\n\n\n\n\nActivity 7: Summary functions p1 (must use the pipe)\n\n#Compute the median of the distance variable per each tail number?\n\n\n#Compute the median of the arr_delay variable per each carrier?\n\n\n#Compute the mean and median of the dep_delay variable per each dest?\n\n\n#Compute the mean and median of the air_time variable per each origin?\n\n\n\nActivity 8: Summary functions p2 (must use the pipe)\n\n# Find min and max of the distance variable for each tail number?\n\n\n# Find min, max and sd of the air_time variable for each carrier?\n\n\n# Find min and max of the dep_delay variable for each month?\n\n\n# Find min, max and sd of the arr_delay variable for each destination?\n\n\nChallenge1: You must use the pipe to complete the challenge and not create any intermediate objects (one big chunk of code)\n\n#Use the flights dataset and apply the following manipulations at the same time using pipes:\n#1) Make sure your dataset has only the following columns: month, day, dep_delay, arr_delay, dest, distance, carrier and air_time\n#2) Reorder your data and show them from the highest arr_delay flight to the smallest one.\n#3) Create a column named distance_km that is equal to distance/1.6\n#4) Per each carrier compute the avg_arr_delay, min_arr_delay, max_arr_delay, sd_arr_delay, median_arr_delay and the number of flights operated.\n#5) Keep in the output only the 5 carriers with the lowest median_arr_delay\n\n\n\nChallenge2: You must use the pipe to complete the challenge and not create any intermediate objects (one big chunk of code)\n\n#Use the flights dataset and apply the following manipulations at the same time using pipes:\n#1) Keep only flights departed from JFK in February\n#2) Make sure your dataset has only the following columns: day, dep_delay, arr_delay, dest,and carrier \n#3) Create a column named final_delay that is equal to arr_delay- dep_delay\n#4) Per each dest compute the avg_final_delay, min_final_delay, max_final_delay, sd_final_delay, median_final_delay and the number of flights landed there.\n#5) Reorder your data and show them from the highest median_final_delay to the smallest one.\n\n\n\n\nWhen not to use the pipe\nThe pipe operator is a powerful tool, but it’s not the only tool at your disposal, and it doesn’t solve every problem! Pipes are most useful for rewriting a fairly short linear sequence of operations. I think you should reach for another tool when:\n\nYour pipes are longer than (say) ten steps. In that case, create intermediate objects with meaningful names. That will make debugging easier, because you can more easily check the intermediate results, and it makes it easier to understand your code, because the variable names can help communicate intent.\nYou have multiple inputs or outputs. If there isn’t one primary object being transformed, but two or more objects being combined together, don’t use the pipe."
  },
  {
    "objectID": "chapter1.html#now-that-you-know-how-to-manipulate-your-data.what-about-learning-how-to-visualize-them-see-you-for-more-in-the-next-chapter",
    "href": "chapter1.html#now-that-you-know-how-to-manipulate-your-data.what-about-learning-how-to-visualize-them-see-you-for-more-in-the-next-chapter",
    "title": "Chapter 1: Manipulations",
    "section": "Now that you know how to manipulate your data.What about learning how to visualize them? See you for more in the next chapter!",
    "text": "Now that you know how to manipulate your data.What about learning how to visualize them? See you for more in the next chapter!"
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "OMIS-482: Predictive Business Analytics With Machine Learning",
    "section": "",
    "text": "Study of advanced topics in predictive business analytics. Topics include data manipulations, data visualizations, and data modeling. Emphasis is on using and mastering powerful predictive analytics software such as R. Students enrolled in this class are expected to learn and efficiently code without supervision. Moreover, they will learn how to apply predictive modelling techniques with machine learning on case studies to see the important real-world implications of predictive analytics in business.."
  },
  {
    "objectID": "course-overview.html#course-description",
    "href": "course-overview.html#course-description",
    "title": "OMIS-482: Predictive Business Analytics With Machine Learning",
    "section": "",
    "text": "Study of advanced topics in predictive business analytics. Topics include data manipulations, data visualizations, and data modeling. Emphasis is on using and mastering powerful predictive analytics software such as R. Students enrolled in this class are expected to learn and efficiently code without supervision. Moreover, they will learn how to apply predictive modelling techniques with machine learning on case studies to see the important real-world implications of predictive analytics in business.."
  },
  {
    "objectID": "course-overview.html#course-resources",
    "href": "course-overview.html#course-resources",
    "title": "OMIS-482: Predictive Business Analytics With Machine Learning",
    "section": "Course Resources",
    "text": "Course Resources\nAll the materials and resources required to learn the topics covered in class will be available on Blackboard. The professor and TA have also developed a course website to enhance your learning experience. Students are responsible for regularly checking the course Blackboard page and the course website. Moreover, you are encouraged to study the materials uploaded or the resources linked in it on a weekly basis. The course will also have a class channel, hosted on Microsoft Teams, to foster interactions and enhance engagement among students and between students and the instructor. Instructions on how to access and use the course website and the Microsoft Teams channel will be provided during the first class.."
  },
  {
    "objectID": "course-overview.html#class-details",
    "href": "course-overview.html#class-details",
    "title": "OMIS-482: Predictive Business Analytics With Machine Learning",
    "section": "Class Details",
    "text": "Class Details\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nWeek’s First Class\nBarsema Hall 333\nTuesday 9:30 - 10:45 A.M\n\n\nWeek’s Second Class\nBarsema Hall 333\nThursday 9:30 - 10:45 A.M"
  },
  {
    "objectID": "in_class.html",
    "href": "in_class.html",
    "title": "One Stop for Materials",
    "section": "",
    "text": "Course Introduction & Getting Started: Access here\n\n\n\n\n\nBasic Manipulations: Access here\n\n\n\n\n\nIntermediate Manipulations: Access here\n\n\n\n\n\nManipulations Review: Access here\n\n\n\n\n\nBasic Visualizations: Access here\n\n\n\n\n\nIntermediate Visualizations: Access here"
  },
  {
    "objectID": "in_class.html#in-class-materials",
    "href": "in_class.html#in-class-materials",
    "title": "One Stop for Materials",
    "section": "",
    "text": "Course Introduction & Getting Started: Access here\n\n\n\n\n\nBasic Manipulations: Access here\n\n\n\n\n\nIntermediate Manipulations: Access here\n\n\n\n\n\nManipulations Review: Access here\n\n\n\n\n\nBasic Visualizations: Access here\n\n\n\n\n\nIntermediate Visualizations: Access here"
  },
  {
    "objectID": "in_class.html#weekly-activities",
    "href": "in_class.html#weekly-activities",
    "title": "One Stop for Materials",
    "section": "Weekly Activities",
    "text": "Weekly Activities\n\nActivity 1\n\nCourse Introduction & Getting Started: Access here\n\n\n\nActivity 2\n\nBasic Manipulations: Access here\n\n\n\nActivity 3\n\nIntermediate Manipulations: Access here\n\n\n\nActivity 4\n\nManipulations Review: Access here\n\n\n\nActivity 5\n\nBasic Visualizations: Access here\n\n\n\nActivity 6\n\nIntermediate Visualizations: Access here"
  },
  {
    "objectID": "practice_R_with_quarto-live.html",
    "href": "practice_R_with_quarto-live.html",
    "title": "R Practise",
    "section": "",
    "text": "This interface helps you to improve your R skills. Here you can access to a data set called starwars"
  },
  {
    "objectID": "practice_R_with_quarto-live.html#use-pipes",
    "href": "practice_R_with_quarto-live.html#use-pipes",
    "title": "R Practise",
    "section": "Use Pipes",
    "text": "Use Pipes\n\n\n\n\n\n\nNote:\n\n\n\nIn order to use pipes, use Ctrl + Shift + M on windows (or) Cmd + Shift + M on Mac. If you are practicing from mobile, copy from here: |&gt;"
  },
  {
    "objectID": "useful-links.html",
    "href": "useful-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Download and install R: https://cran.r-project.org/\nDownload and install RStudio: https://posit.co/download/rstudio-desktop/"
  },
  {
    "objectID": "useful-links.html#install-r-and-rstudio",
    "href": "useful-links.html#install-r-and-rstudio",
    "title": "Useful links",
    "section": "",
    "text": "Download and install R: https://cran.r-project.org/\nDownload and install RStudio: https://posit.co/download/rstudio-desktop/"
  },
  {
    "objectID": "useful-links.html#about-r-packages",
    "href": "useful-links.html#about-r-packages",
    "title": "Useful links",
    "section": "About R Packages",
    "text": "About R Packages\n\n\n\nPackage\nSource\n\n\n\n\nData Manipulation\ndplyr.tidyverse.org\n\n\nData Visualization\nggplot2.tidyverse.org\n\n\nData Modeling\nwww.tidymodels.org/packages"
  },
  {
    "objectID": "useful-links.html#cheat-sheets",
    "href": "useful-links.html#cheat-sheets",
    "title": "Useful links",
    "section": "Cheat Sheets",
    "text": "Cheat Sheets\n\nRStudio IDE Cheatsheet: https://rstudio.github.io/cheatsheets/rstudio-ide.pdf\nData transformation with dplyr Cheatsheet: https://rstudio.github.io/cheatsheets/data-transformation.pdf\nData Visualization with ggplot2: https://rstudio.github.io/cheatsheets/data-visualization.pdf"
  },
  {
    "objectID": "useful-links.html#office-hours",
    "href": "useful-links.html#office-hours",
    "title": "Useful links",
    "section": "Office Hours",
    "text": "Office Hours\n\n\n\nInstructor\nBooking URL\n\n\n\n\nDr. B &/or Venkata\nBook Here\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen booking office hours, double-check the name of the staff member you want to book the office hours with using the “Select Staff” drop down. Moreover, please keep in mind that the default office hours format is virtual (MS Teams meeting). If you prefer to meet in person, please check with us our in-person availability before booking."
  }
]